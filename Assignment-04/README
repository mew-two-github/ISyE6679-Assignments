CUDA is a programming language and the architecture of NVIDIA GPUs. This example shows how to

1) load the cuda module
2) compile a single-GPU code
3) submit the job to the Slurm workload management system to run on the cluster

### Basic usage:

1) Load the cuda module:

    ```
    prompt% module load cuda
    ```

The default version of cuda may change over time as NVIDIA releases new versions (1-3 per year). We advise that users not write scripts that force a specific version unless there is a strong compatibility reason.

2) Compile the example:

    ```
    prompt% make
    ```

    The Makefile contains many useful bits of information on how to compile a CUDA code

3) Submit the example to Slurm using the sbatch command:

    ```
    prompt% sbatch cuda.sbatch
    ```

    The submit script cuda.sbatch is selef-explanatory. Note the special role of lines starting with '#SBATCH'.

4) Compare the program output. The Slurm batch job generates a file named `batch.log` showing commands executed. Check this file carefully for error messages that show up between the prologue and epilogue sections. The Slurm batch job also returns any files generated by the user programs; in this case, `myoutput.log'. Compare these files with the reference files named batch.log.ref and myoutput.log.ref.

```
diff batch.log batch.log.ref
diff myoutput.log myoutput.log.ref
```
